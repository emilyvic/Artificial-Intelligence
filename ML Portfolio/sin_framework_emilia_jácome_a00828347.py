# -*- coding: utf-8 -*-
"""Sin Framework - Emilia_Jácome-A00828347.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mR6XGK0iJwqSNgVdJQ8ejnUG2dT3PMeP

Emilia Victoria Jácome Iñiguez

A00828347

**MOMENTO DE RETROALIMENTACIÓN: IMPLEMENTACIÓN DE UNA TÉCNICA DE APRENDIZAJE MÁQUINA SIN EL USO DE UN FRAMEWORK**

#Implementación del Algoritmo (Manual)

#Probar el algoritmo con un DataSet

##Preliminar

###Conexión a Drive
"""

from google.colab import drive
drive.mount('/content/drive')

cd /content/drive/MyDrive/Inteligencia Artificial Avanzada/Datasets

"""###Cargar los datos a data frames"""

import pandas as pd
columns = ["fixed_acidity", "volatile_acidity", "citric_acid", "residual_sugar", "chlorides", "free_sulfur_dioxide", "total_sulfur_dioxide", "density", "pH", "sulphates", "alcohol", "quality"]
df = pd.read_csv('winequality-white.csv') #generar el dataframe con los datos de wine

df.columns = columns

df

df.describe()

"""###Convertir el tipo de dato a float"""

df.astype(float).dtypes

df.info()

"""###Separar el dataset en entrenamiento y validación

Las variables independientes (x) serán: el nivel de acidez volátil en el vino, el nivel de pH, el nivel de sulphatos y el nivel de cloruros, mientras que la variable dependiente (y) será el nivel de alcohol en el vino.

Por lo que se estará intentando determinar el nivel de alcohol en función del las variables independientes declaradas enteriormente en una muestra de 4898 vinos.
"""

x_ = df.volatile_acidity
x2 = df.pH # Columnas volatile_acidity, pH
x3 = df.sulphates
x4 = df.chlorides
#x_ = df.drop(["quality"], axis=1)
y_ = df.alcohol

#Datos de entrenamiento
x_train = x_.iloc[:3918]
x2_train = x2.iloc[:3918]
x3_train = x3.iloc[:3918]
x4_train = x4.iloc[:3918]

y_train = y_.iloc[:3918]

#Datos de validación
x_validate = x_.iloc[3918:]
x2_validate = x2.iloc[3918:]
x3_validate = x3.iloc[3918:]
x4_validate = x4.iloc[3918:]

y_validate = y_.iloc[3918:]

"""###Definición de parámetros e hiperparámetros"""

import math
alpha = 0.00001 

h   = lambda x,theta: theta[0]+theta[1]*x #
j_i = lambda x,y,theta: (y-h(x,theta))**2 #Función de costo

n_train = len(y_train)
n_validate = len(y_validate)

"""##Orden 1

Entrenamiento del modelo de **regresión lineal** de Orden 1 (x) con variables:

*Variable Independiente (x):*
* x1 = Nivel de Acidez

*Variable Dependiente (y):*
* Nivel de Alcohol
"""

theta = [9,11] # Cambiar dependiendo del orden del modelo (un theta para cada dimensión de nuestros datos + 1)

for idx in range(10000):
  acumDelta = []
  acumDeltaX = []
  for x_i, y_i in zip(x_train,y_train):
    acumDelta.append(h(x_i,theta)-y_i)
    acumDeltaX.append((h(x_i,theta)-y_i)*x_i)

  #Sumatorias de las J's
  sJt0 = sum(acumDelta)  
  sJt1 = sum(acumDeltaX)

  #Cálculo de thetas
  theta[0] = theta[0]-alpha/n_train*sJt0
  theta[1] = theta[1]-alpha/n_train*sJt1

print(theta)

"""###Validación - Cálculo de error con la función de costo"""

# Validación
acumDelta = []
for x_i, y_i in zip(x_validate,y_validate):
  acumDelta.append(j_i(x_i,y_i,theta))  

sDelta = sum(acumDelta)  
J_validate = 1/(2*n_validate)*sDelta


# Training
acumDelta = []
for x_i, y_i in zip(x_train,y_train):
  acumDelta.append(j_i(x_i,y_i,theta))  

sDelta = sum(acumDelta)  
J_train = 1/(2*n_train)*sDelta



print("Error J Validación: ", J_validate)
print("Error J Entrenamiento: ", J_train)
print("Valores de theta: ", theta)

"""A través de esta validación, se puede ver que los errores son mínimos con los siguientes valores iniciales de theta:
* theta 0: 9
* thata 1: 11

Ambos errores están por debajo de 3 puntos, por lo que el margen es muy pequeño y esto demuestra un alto nivel de precisión en el modelo.

##Orden 2

Entrenamiento del modelo de **regresión lineal** de Orden 2 (x2) con variables:

*Variable Independiente (x):*
* x1 = Nivel de Acidez
* x2 = 
Nivel de pH

*Variable Dependiente (y):*
* Nivel de Alcohol
"""

theta = [1,0,3] # Agregar un elemento 

h2 = lambda x,theta,x2: theta[0]+theta[1]*x+theta[2]*x2
alpha = 0.0000001

for idx in range(10000):
  acumDelta = []
  acumDeltaX = []
  acumDeltaX2 = []
  for x_i, y_i, x2_i in zip(x_train,y_train,x2_train): # Agregar la nueva dimensión
    acumDelta.append(h2(x_i,theta,x2_i)-y_i)
    acumDeltaX.append((h2(x_i,theta,x2_i)-y_i)*x_i)    
    acumDeltaX2.append((h2(x_i,theta,x2_i)-y_i)*x2_i) # Acumular para el nuevo theta    

  sJt0 = sum(acumDelta)  
  sJt1 = sum(acumDeltaX)
  sJt2 = sum(acumDeltaX2)
  theta[0] = theta[0]-alpha/n_train*sJt0
  theta[1] = theta[1]-alpha/n_train*sJt1
  theta[2] = theta[2]-alpha/n_train*sJt2 # ACtualizar el nuevo theta

print(theta)

"""###Validación - Cálculo de error con la función de costo"""

j2_i = lambda x,y,theta,x2: (h2(x,theta,x2)-y)**2

# Validación
acumDelta = []
for x_i, y_i,x2_i in zip(x_validate,y_validate,x2_validate): #Agregar la nueva dimensión
  acumDelta.append(j2_i(x_i,y_i,theta,x2_i))  
  #Acumular para el nuevo theta
sDelta = sum(acumDelta)  
J_validate = 1/(2*n_validate)*sDelta


# Training
acumDelta = []
for x_i, y_i,x2_i in zip(x_train,y_train,x2_train):
  acumDelta.append(j2_i(x_i,y_i,theta,x2_i))  

sDelta = sum(acumDelta)  
J_train = 1/(2*n_train)*sDelta



print("Error de J Validación: ", J_validate)
print("Error de J Entrenamiento: ",J_train)
print("Valores de theta: ", theta)

"""A través de esta validación, se puede ver que los errores son mínimos con los siguientes valores iniciales de theta:
* theta 0: 1
* theta 1: 0
* theta 2: 3

Ambos errores están por debajo de 1 punto, por lo que el margen es extremadamente pequeño y esto demuestra un alto nivel de precisión en el modelo.

##Orden 4
Entrenamiento del modelo de **regresión lineal** de Orden 4 (x) con variables:

*Variable Independiente (x):*
* x1= Nivel de Acidez
* x2= Nivel de pH
* x3= Nivel de Sulfatos
* x4= Nivel de cloruros

*Variable Dependiente (y):*
* Nivel de Alcohol
"""

theta = [1,1,1,4,65] # Agregar un elemento 

h4 = lambda x,theta,x2,x3,x4: theta[0]+theta[1]*x+theta[2]*x2+theta[3]*x3+theta[4]*x4
alpha = 0.00001

for idx in range(1000):
  acumDelta = []
  acumDeltaX = []
  acumDeltaX2 = []
  acumDeltaX3 = []
  acumDeltaX4 = []
  for x_i, y_i, x2_i, x3_i, x4_i in zip(x_train,y_train,x2_train, x3_train, x4_train): # Agregar la nueva dimensión
    acumDelta.append(h4(x_i,theta,x2_i,x3_i,x4_i)-y_i)
    acumDeltaX.append((h4(x_i,theta,x2_i,x3_i,x4_i)-y_i)*x_i)    
    acumDeltaX2.append((h4(x_i,theta,x2_i,x3_i,x4_i)-y_i)*x2_i) # Acumular para el nuevo theta   
    acumDeltaX3.append((h4(x_i,theta,x2_i,x3_i,x4_i)-y_i)*x3_i) # Acumular para el nuevo theta   
    acumDeltaX4.append((h4(x_i,theta,x2_i,x3_i,x4_i)-y_i)*x4_i) # Acumular para el nuevo theta    

  sJt0 = sum(acumDelta)  
  sJt1 = sum(acumDeltaX)
  sJt2 = sum(acumDeltaX2)
  sJt3 = sum(acumDeltaX3)
  sJt4 = sum(acumDeltaX4)

  theta[0] = theta[0]-alpha/n_train*sJt0
  theta[1] = theta[1]-alpha/n_train*sJt1
  theta[2] = theta[2]-alpha/n_train*sJt2 # ACtualizar el nuevo theta
  theta[3] = theta[3]-alpha/n_train*sJt3 # ACtualizar el nuevo theta
  theta[4] = theta[4]-alpha/n_train*sJt4 # ACtualizar el nuevo theta

print(theta)

"""###Validación - Cálculo de error con la función de costo"""

j4_i = lambda x,y,theta,x2,x3,x4: (h4(x,theta,x2,x3,x4)-y)**4

# Validación
acumDelta = []
for x_i, y_i,x2_i, x3_i, x4_i in zip(x_validate,y_validate,x2_validate,x3_validate,x4_validate): #Agregar la nueva dimensión
  acumDelta.append(j4_i(x_i,y_i,theta,x2_i,x3_i,x4_i))  
  #Acumular para el nuevo theta
sDelta = sum(acumDelta)  
J_validate = 1/(2*n_validate)*sDelta


# Training
acumDelta = []
for x_i, y_i,x2_i, x3_i, x4_i in zip(x_train,y_train,x2_train,x3_train,x4_train):
  acumDelta.append(j4_i(x_i,y_i,theta,x2_i,x3_i,x4_i))  

sDelta = sum(acumDelta)  
J_train = 1/(2*n_train)*sDelta



print("Error de J Validación: ", J_validate)
print("Error de J Train: ", J_train)
print("Valores de theta: ", theta)

"""A través de esta validación, se puede ver que los errores son mínimos con los siguientes valores iniciales de theta:
* theta 0: 1
* theta 1: 1
* theta 2: 1
* theta 3: 4
* theta 4: 65

Ambos errores están por debajo de 121 puntos, por lo que el margen es medio y esto demuestra un nivel de precisión medio en el modelo.

##Conclusión:

El mejor modelo que se utilizó para predecir el nivel de alcohol a partir de una muestra de vinos fue el modelo de regresión lineal de grado 2 ya que es el modelo que presentó el mayor nivel de precisión en sus predicciones a partir de la métrica de desempeño del error cuadrado promedio (MSE). Las variables que se tomaron en consideración para esta predicción fueron: el nivel de acidez y el nivel de pH de los vinos.
"""